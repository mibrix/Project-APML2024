{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trueskill \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use the Monte Carlo method to predict the next step ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   yyyy-mm-dd  HH:MM     team1     team2  score1  score2\n",
      "0  18/08/2018  18:00    Chievo  Juventus       2       3\n",
      "1  18/08/2018  20:30     Lazio    Napoli       1       2\n",
      "2  19/08/2018  18:00    Torino      Roma       0       1\n",
      "3  19/08/2018  20:30  Sassuolo     Inter       1       0\n",
      "4  19/08/2018  20:30     Parma   Udinese       2       2\n"
     ]
    }
   ],
   "source": [
    "# Return +1 if player 1 wins and -1 if player 2 wins\n",
    "data = pd.read_csv(\"SerieA.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TrueSkill environment with zero draw probability\n",
    "env = trueskill.TrueSkill(draw_probability=0)\n",
    "\n",
    "# Dictionary to store ratings for each team\n",
    "ratings = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chievo' 'Juventus' 'Lazio' 'Napoli' 'Torino' 'Roma' 'Sassuolo' 'Inter'\n",
      " 'Parma' 'Udinese' 'Empoli' 'Cagliari' 'Bologna' 'Spal' 'Atalanta'\n",
      " 'Frosinone' 'Milan' 'Sampdoria' 'Genoa' 'Fiorentina']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of unique teams\n",
    "teams = pd.unique(data[['team1', 'team2']].values.ravel())\n",
    "\n",
    "print(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chievo': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Juventus': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Lazio': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Napoli': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Torino': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Roma': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Sassuolo': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Inter': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Parma': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Udinese': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Empoli': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Cagliari': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Bologna': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Spal': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Atalanta': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Frosinone': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Milan': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Sampdoria': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Genoa': trueskill.Rating(mu=25.000, sigma=8.333),\n",
       " 'Fiorentina': trueskill.Rating(mu=25.000, sigma=8.333)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize each team's rating\n",
    "for team in teams:\n",
    "    ratings[team] = env.create_rating()\n",
    "\n",
    "ratings # Each team starts with equal rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte-Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_win_probability(team1_rating, team2_rating, num_simulations=10000):\n",
    "    \"\"\"\n",
    "    Estimates the probability that team1 wins against team2 using Monte Carlo simulation.\n",
    "\n",
    "    Parameters:\n",
    "    - team1_rating: TrueSkill rating object for team1.\n",
    "    - team2_rating: TrueSkill rating object for team2.\n",
    "    - num_simulations: Number of simulations to run.\n",
    "\n",
    "    Returns:\n",
    "    - Probability that team1 wins.\n",
    "    \"\"\"\n",
    "    team1_wins = 0\n",
    "\n",
    "    # Extract mu and sigma for both teams\n",
    "    mu1, sigma1 = team1_rating.mu, team1_rating.sigma\n",
    "    mu2, sigma2 = team2_rating.mu, team2_rating.sigma\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        # Sample performance from normal distributions\n",
    "        perf1 = np.random.normal(mu1, sigma1)\n",
    "        perf2 = np.random.normal(mu2, sigma2)\n",
    "\n",
    "        # Increment team1_wins if team1's performance is higher\n",
    "        if perf1 > perf2:\n",
    "            team1_wins += 1\n",
    "\n",
    "    # Calculate win probability\n",
    "    win_probability = team1_wins / num_simulations\n",
    "\n",
    "    return win_probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate Over the Matches and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy (excluding draws): 65.44%\n"
     ]
    }
   ],
   "source": [
    "# Lists to store results for analysis\n",
    "predictions = []\n",
    "actual_results = []\n",
    "\n",
    "# Iterate over each match\n",
    "for index, row in data.iterrows():\n",
    "    # Extract teams and scores\n",
    "    team1 = row['team1']\n",
    "    team2 = row['team2']\n",
    "    score1 = row['score1']\n",
    "    score2 = row['score2']\n",
    "\n",
    "    # Get current ratings\n",
    "    team1_rating = ratings[team1]\n",
    "    team2_rating = ratings[team2]\n",
    "\n",
    "    # Step 1: Predict the outcome using Monte Carlo simulation\n",
    "    win_prob = monte_carlo_win_probability(team1_rating, team2_rating)\n",
    "\n",
    "    # Make a deterministic prediction based on win probability\n",
    "    if win_prob > 0.5:\n",
    "        prediction = +1  # Predict team1 wins\n",
    "    else:\n",
    "        prediction = -1  # Predict team2 wins\n",
    "\n",
    "    # Append prediction\n",
    "    predictions.append(prediction)\n",
    "\n",
    "    # Step 2: Determine the actual outcome\n",
    "    if score1 > score2:\n",
    "        actual_result = +1  # Team 1 won\n",
    "    elif score1 < score2:\n",
    "        actual_result = -1  # Team 2 won\n",
    "    else:\n",
    "        # Match was a draw\n",
    "        actual_result = 0   # We will exclude this match from analysis\n",
    "\n",
    "\n",
    "    actual_results.append(actual_result)\n",
    "\n",
    "    # Step 3: Update the TrueSkill ratings with the actual match result\n",
    "    if actual_result == +1:\n",
    "        # Team 1 won\n",
    "        ratings[team1], ratings[team2] = env.rate_1vs1(team1_rating, team2_rating)\n",
    "    elif actual_result == -1:\n",
    "        # Team 2 won\n",
    "        ratings[team2], ratings[team1] = env.rate_1vs1(team2_rating, team1_rating)\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "actual_results = np.array(actual_results)\n",
    "\n",
    "# Exclude matches that ended in a draw from accuracy calculation\n",
    "non_draw_indices = actual_results != 0\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predictions[non_draw_indices] == actual_results[non_draw_indices])\n",
    "\n",
    "print(f'Prediction Accuracy (excluding draws): {accuracy * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
